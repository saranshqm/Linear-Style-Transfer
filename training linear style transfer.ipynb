{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class styleLoss(nn.Module):\n",
    "    def forward(self,input,target):\n",
    "        ib,ic,ih,iw = input.size()\n",
    "        iF = input.view(ib,ic,-1)\n",
    "        iMean = torch.mean(iF,dim=2)\n",
    "        iCov = GramMatrix()(input)\n",
    "\n",
    "        tb,tc,th,tw = target.size()\n",
    "        tF = target.view(tb,tc,-1)\n",
    "        tMean = torch.mean(tF,dim=2)\n",
    "        tCov = GramMatrix()(target)\n",
    "\n",
    "        loss = nn.MSELoss(size_average=False)(iMean,tMean) + nn.MSELoss(size_average=False)(iCov,tCov)\n",
    "        return loss/tb\n",
    "\n",
    "class GramMatrix(nn.Module):\n",
    "    def forward(self,input):\n",
    "        b, c, h, w = input.size()\n",
    "        f = input.view(b,c,h*w) # bxcx(hxw)\n",
    "        # torch.bmm(batch1, batch2, out=None)   #\n",
    "        # batch1: bxmxp, batch2: bxpxn -> bxmxn #\n",
    "        G = torch.bmm(f,f.transpose(1,2)) # f: bxcx(hxw), f.transpose: bx(hxw)xc -> bxcxc\n",
    "        return G.div_(c*h*w)\n",
    "\n",
    "class LossCriterion(nn.Module):\n",
    "    def __init__(self,style_layers,content_layers,style_weight,content_weight):\n",
    "        super(LossCriterion,self).__init__()\n",
    "\n",
    "        self.style_layers = style_layers\n",
    "        self.content_layers = content_layers\n",
    "        self.style_weight = style_weight\n",
    "        self.content_weight = content_weight\n",
    "\n",
    "        self.styleLosses = [styleLoss()] * len(style_layers)\n",
    "        self.contentLosses = [nn.MSELoss()] * len(content_layers)\n",
    "\n",
    "    def forward(self,tF,sF,cF):\n",
    "        # content loss\n",
    "        totalContentLoss = 0\n",
    "        for i,layer in enumerate(self.content_layers):\n",
    "            cf_i = cF[layer]\n",
    "            cf_i = cf_i.detach()\n",
    "            tf_i = tF[layer]\n",
    "            loss_i = self.contentLosses[i]\n",
    "            totalContentLoss += loss_i(tf_i,cf_i)\n",
    "        totalContentLoss = totalContentLoss * self.content_weight\n",
    "\n",
    "        # style loss\n",
    "        totalStyleLoss = 0\n",
    "        for i,layer in enumerate(self.style_layers):\n",
    "            sf_i = sF[layer]\n",
    "            sf_i = sf_i.detach()\n",
    "            tf_i = tF[layer]\n",
    "            loss_i = self.styleLosses[i]\n",
    "            totalStyleLoss += loss_i(tf_i,sf_i)\n",
    "        totalStyleLoss = totalStyleLoss * self.style_weight\n",
    "        loss = totalStyleLoss + totalContentLoss\n",
    "\n",
    "        return loss,totalStyleLoss,totalContentLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from PIL import Image\n",
    "import scipy.sparse.linalg\n",
    "from cv2.ximgproc import jointBilateralFilter\n",
    "\n",
    "# from torch.utils.serialization import load_lua\n",
    "\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "def whiten(cF):\n",
    "    cFSize = cF.size()\n",
    "    c_mean = torch.mean(cF,1) # c x (h x w)\n",
    "    c_mean = c_mean.unsqueeze(1).expand_as(cF)\n",
    "    cF = cF - c_mean\n",
    "\n",
    "    contentConv = torch.mm(cF,cF.t()).div(cFSize[1]-1) + torch.eye(cFSize[0]).double()\n",
    "    c_u,c_e,c_v = torch.svd(contentConv,some=False)\n",
    "\n",
    "    k_c = cFSize[0]\n",
    "    for i in range(cFSize[0]):\n",
    "        if c_e[i] < 0.00001:\n",
    "            k_c = i\n",
    "            break\n",
    "\n",
    "    c_d = (c_e[0:k_c]).pow(-0.5)\n",
    "    step1 = torch.mm(c_v[:,0:k_c],torch.diag(c_d))\n",
    "    step2 = torch.mm(step1,(c_v[:,0:k_c].t()))\n",
    "    whiten_cF = torch.mm(step2,cF)\n",
    "    return whiten_cF\n",
    "\n",
    "def numpy2cv2(cont,style,prop,width,height):\n",
    "    cont = cont.transpose((1,2,0))\n",
    "    cont = cont[...,::-1]\n",
    "    cont = cont * 255\n",
    "    cont = cv2.resize(cont,(width,height))\n",
    "    #cv2.resize(iimg,(width,height))\n",
    "    style = style.transpose((1,2,0))\n",
    "    style = style[...,::-1]\n",
    "    style = style * 255\n",
    "    style = cv2.resize(style,(width,height))\n",
    "\n",
    "    prop = prop.transpose((1,2,0))\n",
    "    prop = prop[...,::-1]\n",
    "    prop = prop * 255\n",
    "    prop = cv2.resize(prop,(width,height))\n",
    "\n",
    "    #return np.concatenate((cont,np.concatenate((style,prop),axis=1)),axis=1)\n",
    "    return prop,cont\n",
    "\n",
    "def makeVideo(content,style,props,outf):\n",
    "    print('Stack transferred frames back to video...')\n",
    "#     print(content[0].shape)\n",
    "    layers,height,width = content[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    video = cv2.VideoWriter(os.path.join(outf,'transfer.avi'),fourcc,10.0,(width,height))\n",
    "    ori_video = cv2.VideoWriter(os.path.join(outf,'content.avi'),fourcc,10.0,(width,height))\n",
    "    for j in range(len(content)):\n",
    "        prop,cont = numpy2cv2(content[j],style,props[j],width,height)\n",
    "        cv2.imwrite('prop.png',prop)\n",
    "        cv2.imwrite('content.png',cont)\n",
    "        # TODO: this is ugly, fix this\n",
    "        imgj = cv2.imread('prop.png')\n",
    "        imgc = cv2.imread('content.png')\n",
    "\n",
    "        video.write(imgj)\n",
    "        ori_video.write(imgc)\n",
    "        # RGB or BRG, yuks\n",
    "    video.release()\n",
    "    ori_video.release()\n",
    "    os.remove('prop.png')\n",
    "    os.remove('content.png')\n",
    "    print('Transferred video saved at %s.'%outf)\n",
    "\n",
    "def print_options(opt):\n",
    "    message = ''\n",
    "    message += '----------------- Options ---------------\\n'\n",
    "    for k, v in sorted(vars(opt).items()):\n",
    "        comment = ''\n",
    "        message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n",
    "    message += '----------------- End -------------------'\n",
    "    print(message)\n",
    "\n",
    "    # save to the disk\n",
    "    expr_dir = os.path.join(outf)\n",
    "    os.makedirs(expr_dir,exist_ok=True)\n",
    "    file_name = os.path.join(expr_dir, 'txt')\n",
    "    with open(file_name, 'wt') as opt_file:\n",
    "        opt_file.write(message)\n",
    "        opt_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,layer,matrixSize=32):\n",
    "        super(CNN,self).__init__()\n",
    "        if(layer == 'r31'):\n",
    "            # 256x64x64\n",
    "            self.convs = nn.Sequential(nn.Conv2d(256,128,3,1,1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Conv2d(128,64,3,1,1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Conv2d(64,matrixSize,3,1,1))\n",
    "        elif(layer == 'r41'):\n",
    "            # 512x32x32\n",
    "            self.convs = nn.Sequential(nn.Conv2d(512,256,3,1,1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Conv2d(256,128,3,1,1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Conv2d(128,matrixSize,3,1,1))\n",
    "\n",
    "        # 32x8x8\n",
    "        self.fc = nn.Linear(matrixSize*matrixSize,matrixSize*matrixSize)\n",
    "        #self.fc = nn.Linear(32*64,256*256)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.convs(x)\n",
    "        # 32x8x8\n",
    "        b,c,h,w = out.size()\n",
    "        out = out.view(b,c,-1)\n",
    "        # 32x64\n",
    "        out = torch.bmm(out,out.transpose(1,2)).div(h*w)\n",
    "        # 32x32\n",
    "        out = out.view(out.size(0),-1)\n",
    "        return self.fc(out)\n",
    "\n",
    "class MulLayer(nn.Module):\n",
    "    def __init__(self,layer,matrixSize=32):\n",
    "        super(MulLayer,self).__init__()\n",
    "        self.snet = CNN(layer,matrixSize)\n",
    "        self.cnet = CNN(layer,matrixSize)\n",
    "        self.matrixSize = matrixSize\n",
    "\n",
    "        if(layer == 'r41'):\n",
    "            self.compress = nn.Conv2d(512,matrixSize,1,1,0)\n",
    "            self.unzip = nn.Conv2d(matrixSize,512,1,1,0)\n",
    "        elif(layer == 'r31'):\n",
    "            self.compress = nn.Conv2d(256,matrixSize,1,1,0)\n",
    "            self.unzip = nn.Conv2d(matrixSize,256,1,1,0)\n",
    "        self.transmatrix = None\n",
    "\n",
    "    def forward(self,cF,sF,trans=True):\n",
    "        cFBK = cF.clone()\n",
    "        cb,cc,ch,cw = cF.size()\n",
    "        cFF = cF.view(cb,cc,-1)\n",
    "        cMean = torch.mean(cFF,dim=2,keepdim=True)\n",
    "        cMean = cMean.unsqueeze(3)\n",
    "        cMean = cMean.expand_as(cF)\n",
    "        cF = cF - cMean\n",
    "\n",
    "        sb,sc,sh,sw = sF.size()\n",
    "        sFF = sF.view(sb,sc,-1)\n",
    "        sMean = torch.mean(sFF,dim=2,keepdim=True)\n",
    "        sMean = sMean.unsqueeze(3)\n",
    "        sMeanC = sMean.expand_as(cF)\n",
    "        sMeanS = sMean.expand_as(sF)\n",
    "        sF = sF - sMeanS\n",
    "\n",
    "\n",
    "        compress_content = self.compress(cF)\n",
    "        b,c,h,w = compress_content.size()\n",
    "        compress_content = compress_content.view(b,c,-1)\n",
    "\n",
    "        if(trans):\n",
    "            cMatrix = self.cnet(cF)\n",
    "            sMatrix = self.snet(sF)\n",
    "\n",
    "            sMatrix = sMatrix.view(sMatrix.size(0),self.matrixSize,self.matrixSize)\n",
    "            cMatrix = cMatrix.view(cMatrix.size(0),self.matrixSize,self.matrixSize)\n",
    "            transmatrix = torch.bmm(sMatrix,cMatrix)\n",
    "            transfeature = torch.bmm(transmatrix,compress_content).view(b,c,h,w)\n",
    "            out = self.unzip(transfeature.view(b,c,h,w))\n",
    "            out = out + sMeanC\n",
    "            return out, transmatrix\n",
    "        else:\n",
    "            out = self.unzip(compress_content.view(b,c,h,w))\n",
    "            out = out + cMean\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self,dataPath,loadSize,fineSize,test=True,video=True):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.dataPath = dataPath\n",
    "        self.image_list = [x for x in os.listdir(dataPath) if is_image_file(x)]\n",
    "        self.image_list = sorted(self.image_list)\n",
    "        if(video):\n",
    "            self.image_list = sorted(self.image_list)\n",
    "        if not test:\n",
    "            self.transform = transforms.Compose([\n",
    "            \t\t         transforms.Resize(fineSize),\n",
    "            \t\t         transforms.RandomCrop(fineSize),\n",
    "                             transforms.RandomHorizontalFlip(),\n",
    "            \t\t         transforms.ToTensor()])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "            \t\t         transforms.Resize(fineSize),\n",
    "            \t\t         transforms.ToTensor()])\n",
    "\n",
    "        self.test = test\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        dataPath = os.path.join(self.dataPath,self.image_list[index])\n",
    "\n",
    "        Img = default_loader(dataPath)\n",
    "        ImgA = self.transform(Img)\n",
    "\n",
    "        imgName = self.image_list[index]\n",
    "        imgName = imgName.split('.')[0]\n",
    "        return ImgA,imgName\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class encoder3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder3,self).__init__()\n",
    "        # vgg\n",
    "        # 224 x 224\n",
    "        self.conv1 = nn.Conv2d(3,3,1,1,0)\n",
    "        self.reflecPad1 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        # 226 x 226\n",
    "\n",
    "        self.conv2 = nn.Conv2d(3,64,3,1,0)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad3 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv3 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2,stride=2,return_indices = True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad4 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad5 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.maxPool2 = nn.MaxPool2d(kernel_size=2,stride=2,return_indices = True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad6 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv6 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.reflecPad1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.reflecPad3(out)\n",
    "        out = self.conv3(out)\n",
    "        pool1 = self.relu3(out)\n",
    "        out,pool_idx = self.maxPool(pool1)\n",
    "        out = self.reflecPad4(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.reflecPad5(out)\n",
    "        out = self.conv5(out)\n",
    "        pool2 = self.relu5(out)\n",
    "        out,pool_idx2 = self.maxPool2(pool2)\n",
    "        out = self.reflecPad6(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.relu6(out)\n",
    "        return out\n",
    "\n",
    "class decoder3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder3,self).__init__()\n",
    "        # decoder\n",
    "        self.reflecPad7 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv7 = nn.Conv2d(256,128,3,1,0)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.unpool = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad8 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv8 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.relu8 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad9 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv9 = nn.Conv2d(128,64,3,1,0)\n",
    "        self.relu9 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad10 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv10 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.relu10 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad11 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv11 = nn.Conv2d(64,3,3,1,0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = {}\n",
    "        out = self.reflecPad7(x)\n",
    "        out = self.conv7(out)\n",
    "        out = self.relu7(out)\n",
    "        out = self.unpool(out)\n",
    "        out = self.reflecPad8(out)\n",
    "        out = self.conv8(out)\n",
    "        out = self.relu8(out)\n",
    "        out = self.reflecPad9(out)\n",
    "        out = self.conv9(out)\n",
    "        out_relu9 = self.relu9(out)\n",
    "        out = self.unpool2(out_relu9)\n",
    "        out = self.reflecPad10(out)\n",
    "        out = self.conv10(out)\n",
    "        out = self.relu10(out)\n",
    "        out = self.reflecPad11(out)\n",
    "        out = self.conv11(out)\n",
    "        return out\n",
    "\n",
    "class encoder4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder4,self).__init__()\n",
    "        # vgg\n",
    "        # 224 x 224\n",
    "        self.conv1 = nn.Conv2d(3,3,1,1,0)\n",
    "        self.reflecPad1 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        # 226 x 226\n",
    "\n",
    "        self.conv2 = nn.Conv2d(3,64,3,1,0)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad3 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv3 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad4 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad5 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.maxPool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad6 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv6 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad7 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv7 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad8 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv8 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu8 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad9 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv9 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu9 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.maxPool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.reflecPad10 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv10 = nn.Conv2d(256,512,3,1,0)\n",
    "        self.relu10 = nn.ReLU(inplace=True)\n",
    "        # 28 x 28\n",
    "    def forward(self,x,sF=None,matrix11=None,matrix21=None,matrix31=None):\n",
    "        output = {}\n",
    "        out = self.conv1(x)\n",
    "        out = self.reflecPad1(out)\n",
    "        out = self.conv2(out)\n",
    "        output['r11'] = self.relu2(out)\n",
    "        out = self.reflecPad7(output['r11'])\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        output['r12'] = self.relu3(out)\n",
    "\n",
    "        output['p1'] = self.maxPool(output['r12'])\n",
    "        out = self.reflecPad4(output['p1'])\n",
    "        out = self.conv4(out)\n",
    "        output['r21'] = self.relu4(out)\n",
    "        out = self.reflecPad7(output['r21'])\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        output['r22'] = self.relu5(out)\n",
    "\n",
    "        output['p2'] = self.maxPool2(output['r22'])\n",
    "        out = self.reflecPad6(output['p2'])\n",
    "        out = self.conv6(out)\n",
    "        output['r31'] = self.relu6(out)\n",
    "        if(matrix31 is not None):\n",
    "            feature3,transmatrix3 = matrix31(output['r31'],sF['r31'])\n",
    "            out = self.reflecPad7(feature3)\n",
    "        else:\n",
    "            out = self.reflecPad7(output['r31'])\n",
    "        out = self.conv7(out)\n",
    "        output['r32'] = self.relu7(out)\n",
    "\n",
    "        out = self.reflecPad8(output['r32'])\n",
    "        out = self.conv8(out)\n",
    "        output['r33'] = self.relu8(out)\n",
    "\n",
    "        out = self.reflecPad9(output['r33'])\n",
    "        out = self.conv9(out)\n",
    "        output['r34'] = self.relu9(out)\n",
    "\n",
    "        output['p3'] = self.maxPool3(output['r34'])\n",
    "        out = self.reflecPad10(output['p3'])\n",
    "        out = self.conv10(out)\n",
    "        output['r41'] = self.relu10(out)\n",
    "\n",
    "        return output\n",
    "\n",
    "class decoder4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder4,self).__init__()\n",
    "        # decoder\n",
    "        self.reflecPad11 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv11 = nn.Conv2d(512,256,3,1,0)\n",
    "        self.relu11 = nn.ReLU(inplace=True)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.unpool = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad12 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv12 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu12 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad13 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv13 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu13 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad14 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv14 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu14 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad15 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv15 = nn.Conv2d(256,128,3,1,0)\n",
    "        self.relu15 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.unpool2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad16 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv16 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.relu16 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad17 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv17 = nn.Conv2d(128,64,3,1,0)\n",
    "        self.relu17 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.unpool3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad18 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv18 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.relu18 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad19 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv19 = nn.Conv2d(64,3,3,1,0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # decoder\n",
    "        out = self.reflecPad11(x)\n",
    "        out = self.conv11(out)\n",
    "        out = self.relu11(out)\n",
    "        out = self.unpool(out)\n",
    "        out = self.reflecPad12(out)\n",
    "        out = self.conv12(out)\n",
    "\n",
    "        out = self.relu12(out)\n",
    "        out = self.reflecPad13(out)\n",
    "        out = self.conv13(out)\n",
    "        out = self.relu13(out)\n",
    "        out = self.reflecPad14(out)\n",
    "        out = self.conv14(out)\n",
    "        out = self.relu14(out)\n",
    "        out = self.reflecPad15(out)\n",
    "        out = self.conv15(out)\n",
    "        out = self.relu15(out)\n",
    "        out = self.unpool2(out)\n",
    "        out = self.reflecPad16(out)\n",
    "        out = self.conv16(out)\n",
    "        out = self.relu16(out)\n",
    "        out = self.reflecPad17(out)\n",
    "        out = self.conv17(out)\n",
    "        out = self.relu17(out)\n",
    "        out = self.unpool3(out)\n",
    "        out = self.reflecPad18(out)\n",
    "        out = self.conv18(out)\n",
    "        out = self.relu18(out)\n",
    "        out = self.reflecPad19(out)\n",
    "        out = self.conv19(out)\n",
    "        return out\n",
    "\n",
    "class decoder4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder4,self).__init__()\n",
    "        # decoder\n",
    "        self.reflecPad11 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv11 = nn.Conv2d(512,256,3,1,0)\n",
    "        self.relu11 = nn.ReLU(inplace=True)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.unpool = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad12 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv12 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu12 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad13 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv13 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu13 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad14 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv14 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu14 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad15 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv15 = nn.Conv2d(256,128,3,1,0)\n",
    "        self.relu15 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.unpool2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad16 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv16 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.relu16 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad17 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv17 = nn.Conv2d(128,64,3,1,0)\n",
    "        self.relu17 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.unpool3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad18 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv18 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.relu18 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad19 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv19 = nn.Conv2d(64,3,3,1,0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # decoder\n",
    "        out = self.reflecPad11(x)\n",
    "        out = self.conv11(out)\n",
    "        out = self.relu11(out)\n",
    "        out = self.unpool(out)\n",
    "        out = self.reflecPad12(out)\n",
    "        out = self.conv12(out)\n",
    "\n",
    "        out = self.relu12(out)\n",
    "        out = self.reflecPad13(out)\n",
    "        out = self.conv13(out)\n",
    "        out = self.relu13(out)\n",
    "        out = self.reflecPad14(out)\n",
    "        out = self.conv14(out)\n",
    "        out = self.relu14(out)\n",
    "        out = self.reflecPad15(out)\n",
    "        out = self.conv15(out)\n",
    "        out = self.relu15(out)\n",
    "        out = self.unpool2(out)\n",
    "        out = self.reflecPad16(out)\n",
    "        out = self.conv16(out)\n",
    "        out = self.relu16(out)\n",
    "        out = self.reflecPad17(out)\n",
    "        out = self.conv17(out)\n",
    "        out = self.relu17(out)\n",
    "        out = self.unpool3(out)\n",
    "        out = self.reflecPad18(out)\n",
    "        out = self.conv18(out)\n",
    "        out = self.relu18(out)\n",
    "        out = self.reflecPad19(out)\n",
    "        out = self.conv19(out)\n",
    "        return out\n",
    "\n",
    "class loss_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(loss_network,self).__init__()\n",
    "        # vgg\n",
    "        # 224 x 224\n",
    "        self.conv1 = nn.Conv2d(3,3,1,1,0)\n",
    "        self.reflecPad1 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        # 226 x 226\n",
    "\n",
    "        self.conv2 = nn.Conv2d(3,64,3,1,0)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.reflecPad3 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv3 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        # 224 x 224\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad4 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.reflecPad5 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        # 112 x 112\n",
    "\n",
    "        self.maxPool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad6 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv6 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad7 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv7 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad8 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv8 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu8 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad9 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv9 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu9 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.maxPool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.reflecPad10 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv10 = nn.Conv2d(256,512,3,1,0)\n",
    "        self.relu10 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad11 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv11 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu11 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad12 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv12 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu12 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad13 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv13 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu13 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.maxPool4 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.reflecPad14 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv14 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu14 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x,sF=None,contentV256=None,styleV256=None,matrix11=None,matrix21=None,matrix31=None):\n",
    "        output = {}\n",
    "        out = self.conv1(x)\n",
    "        out = self.reflecPad1(out)\n",
    "        out = self.conv2(out)\n",
    "        output['r11'] = self.relu2(out)\n",
    "        out = self.reflecPad7(output['r11'])\n",
    "\n",
    "        #out = self.reflecPad3(output['r11'])\n",
    "        out = self.conv3(out)\n",
    "        output['r12'] = self.relu3(out)\n",
    "\n",
    "        output['p1'] = self.maxPool(output['r12'])\n",
    "        out = self.reflecPad4(output['p1'])\n",
    "        out = self.conv4(out)\n",
    "        output['r21'] = self.relu4(out)\n",
    "        out = self.reflecPad7(output['r21'])\n",
    "\n",
    "        #out = self.reflecPad5(output['r21'])\n",
    "        out = self.conv5(out)\n",
    "        output['r22'] = self.relu5(out)\n",
    "\n",
    "        output['p2'] = self.maxPool2(output['r22'])\n",
    "        out = self.reflecPad6(output['p2'])\n",
    "        out = self.conv6(out)\n",
    "        output['r31'] = self.relu6(out)\n",
    "        if(styleV256 is not None):\n",
    "            feature = matrix31(output['r31'],sF['r31'],contentV256,styleV256)\n",
    "            out = self.reflecPad7(feature)\n",
    "        else:\n",
    "            out = self.reflecPad7(output['r31'])\n",
    "        out = self.conv7(out)\n",
    "        output['r32'] = self.relu7(out)\n",
    "\n",
    "        out = self.reflecPad8(output['r32'])\n",
    "        out = self.conv8(out)\n",
    "        output['r33'] = self.relu8(out)\n",
    "\n",
    "        out = self.reflecPad9(output['r33'])\n",
    "        out = self.conv9(out)\n",
    "        output['r34'] = self.relu9(out)\n",
    "\n",
    "        output['p3'] = self.maxPool3(output['r34'])\n",
    "        out = self.reflecPad10(output['p3'])\n",
    "        out = self.conv10(out)\n",
    "        output['r41'] = self.relu10(out)\n",
    "\n",
    "        out = self.reflecPad11(output['r41'])\n",
    "        out = self.conv11(out)\n",
    "        output['r42'] = self.relu11(out)\n",
    "\n",
    "        out = self.reflecPad12(output['r42'])\n",
    "        out = self.conv12(out)\n",
    "        output['r43'] = self.relu12(out)\n",
    "\n",
    "        out = self.reflecPad13(output['r43'])\n",
    "        out = self.conv13(out)\n",
    "        output['r44'] = self.relu13(out)\n",
    "\n",
    "        output['p4'] = self.maxPool4(output['r44'])\n",
    "\n",
    "        out = self.reflecPad14(output['p4'])\n",
    "        out = self.conv14(out)\n",
    "        output['r51'] = self.relu14(out)\n",
    "        return output\n",
    "\n",
    "class decoder5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder5,self).__init__()\n",
    "\n",
    "        # decoder\n",
    "        self.reflecPad15 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv15 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu15 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.reflecPad16 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv16 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu16 = nn.ReLU(inplace=True)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.reflecPad17 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv17 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu17 = nn.ReLU(inplace=True)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.reflecPad18 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv18 = nn.Conv2d(512,512,3,1,0)\n",
    "        self.relu18 = nn.ReLU(inplace=True)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.reflecPad19 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv19 = nn.Conv2d(512,256,3,1,0)\n",
    "        self.relu19 = nn.ReLU(inplace=True)\n",
    "        # 28 x 28\n",
    "\n",
    "        self.unpool2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad20 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv20 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu20 = nn.ReLU(inplace=True)\n",
    "        # 56 x 56\n",
    "\n",
    "        self.reflecPad21 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv21 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu21 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad22 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv22 = nn.Conv2d(256,256,3,1,0)\n",
    "        self.relu22 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad23 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv23 = nn.Conv2d(256,128,3,1,0)\n",
    "        self.relu23 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        # 112 X 112\n",
    "\n",
    "        self.reflecPad24 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv24 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.relu24 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad25 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv25 = nn.Conv2d(128,64,3,1,0)\n",
    "        self.relu25 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "\n",
    "        self.reflecPad26 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv26 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.relu26 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad27 = nn.ReflectionPad2d((1,1,1,1))\n",
    "        self.conv27 = nn.Conv2d(64,3,3,1,0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # decoder\n",
    "        out = self.reflecPad15(x)\n",
    "        out = self.conv15(out)\n",
    "        out = self.relu15(out)\n",
    "        out = self.unpool(out)\n",
    "        out = self.reflecPad16(out)\n",
    "        out = self.conv16(out)\n",
    "        out = self.relu16(out)\n",
    "        out = self.reflecPad17(out)\n",
    "        out = self.conv17(out)\n",
    "        out = self.relu17(out)\n",
    "        out = self.reflecPad18(out)\n",
    "        out = self.conv18(out)\n",
    "        out = self.relu18(out)\n",
    "        out = self.reflecPad19(out)\n",
    "        out = self.conv19(out)\n",
    "        out = self.relu19(out)\n",
    "        out = self.unpool2(out)\n",
    "        out = self.reflecPad20(out)\n",
    "        out = self.conv20(out)\n",
    "        out = self.relu20(out)\n",
    "        out = self.reflecPad21(out)\n",
    "        out = self.conv21(out)\n",
    "        out = self.relu21(out)\n",
    "        out = self.reflecPad22(out)\n",
    "        out = self.conv22(out)\n",
    "        out = self.relu22(out)\n",
    "        out = self.reflecPad23(out)\n",
    "        out = self.conv23(out)\n",
    "        out = self.relu23(out)\n",
    "        out = self.unpool3(out)\n",
    "        out = self.reflecPad24(out)\n",
    "        out = self.conv24(out)\n",
    "        out = self.relu24(out)\n",
    "        out = self.reflecPad25(out)\n",
    "        out = self.conv25(out)\n",
    "        out = self.relu25(out)\n",
    "        out = self.unpool4(out)\n",
    "        out = self.reflecPad26(out)\n",
    "        out = self.conv26(out)\n",
    "        out = self.relu26(out)\n",
    "        out = self.reflecPad27(out)\n",
    "        out = self.conv27(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARANSH\\Anaconda3\\envs\\saransh\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: [100000/1] Loss: 10.8579 contentLoss: 1.7874 styleLoss: 9.0705 Learng Rate is 0.000100\n",
      "Iteration: [100000/2] Loss: 10.6920 contentLoss: 2.2069 styleLoss: 8.4850 Learng Rate is 0.000100\n",
      "Iteration: [100000/3] Loss: 10.5479 contentLoss: 2.1307 styleLoss: 8.4172 Learng Rate is 0.000100\n",
      "Iteration: [100000/4] Loss: 8.7353 contentLoss: 1.9910 styleLoss: 6.7443 Learng Rate is 0.000100\n",
      "Iteration: [100000/5] Loss: 6.1243 contentLoss: 1.6737 styleLoss: 4.4506 Learng Rate is 0.000100\n",
      "Iteration: [100000/6] Loss: 4.5267 contentLoss: 1.4485 styleLoss: 3.0782 Learng Rate is 0.000100\n",
      "Iteration: [100000/7] Loss: 4.1905 contentLoss: 1.3130 styleLoss: 2.8775 Learng Rate is 0.000100\n",
      "Iteration: [100000/8] Loss: 4.8126 contentLoss: 1.5576 styleLoss: 3.2550 Learng Rate is 0.000100\n",
      "Iteration: [100000/9] Loss: 22.4423 contentLoss: 5.4142 styleLoss: 17.0281 Learng Rate is 0.000100\n",
      "Iteration: [100000/10] Loss: 5.5472 contentLoss: 2.3595 styleLoss: 3.1878 Learng Rate is 0.000100\n",
      "Iteration: [100000/11] Loss: 4.2369 contentLoss: 1.7340 styleLoss: 2.5029 Learng Rate is 0.000100\n",
      "Iteration: [100000/12] Loss: 4.1396 contentLoss: 1.3358 styleLoss: 2.8038 Learng Rate is 0.000100\n",
      "Iteration: [100000/13] Loss: 4.2892 contentLoss: 1.3768 styleLoss: 2.9124 Learng Rate is 0.000100\n",
      "Iteration: [100000/14] Loss: 4.5842 contentLoss: 1.4058 styleLoss: 3.1784 Learng Rate is 0.000100\n",
      "Iteration: [100000/15] Loss: 5.2264 contentLoss: 1.2444 styleLoss: 3.9820 Learng Rate is 0.000100\n",
      "Iteration: [100000/16] Loss: 5.2660 contentLoss: 1.5340 styleLoss: 3.7319 Learng Rate is 0.000100\n",
      "Iteration: [100000/17] Loss: 5.3869 contentLoss: 1.5730 styleLoss: 3.8140 Learng Rate is 0.000100\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "vgg_dir = 'D:/Swayatt Robots/work/work done/task 2 style transfer/style transfer/linear style training/vgg_r41.pth'\n",
    "loss_network_dir = 'D:/Swayatt Robots/work/work done/task 2 style transfer/style transfer/linear style training/vgg_r51.pth'\n",
    "decoder_dir = 'D:/Swayatt Robots/work/work done/task 2 style transfer/style transfer/linear style training/dec_r41.pth'\n",
    "\n",
    "\n",
    "stylePath = 'D:/Swayatt Robots/work/work done/task 2 style transfer/day_to_night/models/DNIM/Image/night/night/'\n",
    "contentPath = 'D:/Swayatt Robots/work/work done/task 2 style transfer/day_to_night/models/DNIM/Image/day/day/'\n",
    "\n",
    "outf = 'D:/Swayatt Robots/work/work done/task 2 style transfer/style transfer/linear style training/'\n",
    "content_layers = 'r41'\n",
    "\n",
    "style_layers = \"r11,r21,r31,r41\"\n",
    "batchSize = 2\n",
    "\n",
    "niter = 100000\n",
    "\n",
    "loadSize = 300\n",
    "fineSize = 256\n",
    "\n",
    "lr = 0.0001\n",
    "content_weight = 1.0\n",
    "\n",
    "style_weight = 0.02\n",
    "\n",
    "\n",
    "log_interval = 50\n",
    "\n",
    "gpu_id = 0\n",
    "\n",
    "save_interval = 5000\n",
    "\n",
    "layer = 'r41'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################# PREPARATIONS #################\n",
    "# opt = parser.parse_args()\n",
    "content_layers = content_layers.split(',')\n",
    "style_layers = style_layers.split(',')\n",
    "cuda = torch.cuda.is_available()\n",
    "if(cuda):\n",
    "    torch.cuda.set_device(gpu_id)\n",
    "\n",
    "os.makedirs(outf,exist_ok=True)\n",
    "cudnn.benchmark = True\n",
    "# print(\"1\")\n",
    "\n",
    "################# DATA #################\n",
    "content_dataset = Dataset(contentPath,loadSize,fineSize)\n",
    "content_loader_ = torch.utils.data.DataLoader(dataset     = content_dataset,\n",
    "                                              batch_size  = batchSize,\n",
    "                                              shuffle     = False,\n",
    "                                              num_workers = 0,\n",
    "                                              drop_last   = True)\n",
    "# print('2')\n",
    "content_loader = iter(content_loader_)\n",
    "# print('3')\n",
    "style_dataset = Dataset(stylePath,loadSize,fineSize)\n",
    "# print('4')\n",
    "style_loader_ = torch.utils.data.DataLoader(dataset     = style_dataset,\n",
    "                                            batch_size  = batchSize,\n",
    "                                            shuffle     = False,\n",
    "                                            num_workers = 0,\n",
    "                                            drop_last   = True)\n",
    "# print('5')\n",
    "style_loader = iter(style_loader_)\n",
    "# print('6')\n",
    "################# MODEL #################\n",
    "vgg5 = loss_network()\n",
    "if(layer == 'r31'):\n",
    "    matrix = MulLayer('r31')\n",
    "    vgg = encoder3()\n",
    "    dec = decoder3()\n",
    "elif(layer == 'r41'):\n",
    "    matrix = MulLayer('r41')\n",
    "    vgg = encoder4()\n",
    "    dec = decoder4()\n",
    "    \n",
    "# print('7')\n",
    "vgg.load_state_dict(torch.load(vgg_dir))\n",
    "# print('8')\n",
    "dec.load_state_dict(torch.load(decoder_dir))\n",
    "# print('9')\n",
    "vgg5.load_state_dict(torch.load(loss_network_dir))\n",
    "# print('10')\n",
    "\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in vgg5.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in dec.parameters():\n",
    "    param.requires_grad = False\n",
    "# print('11')\n",
    "################# LOSS & OPTIMIZER #################\n",
    "criterion = LossCriterion(style_layers,\n",
    "                          content_layers,\n",
    "                          style_weight,\n",
    "                          content_weight)\n",
    "optimizer = optim.Adam(matrix.parameters(), lr)\n",
    "# print('12')\n",
    "################# GLOBAL VARIABLE #################\n",
    "contentV = torch.Tensor(batchSize,3,fineSize,fineSize)\n",
    "styleV = torch.Tensor(batchSize,3,fineSize,fineSize)\n",
    "# print('13')\n",
    "\n",
    "\n",
    "\n",
    "################# GPU  #################\n",
    "if(cuda):\n",
    "    vgg.cuda()\n",
    "    dec.cuda()\n",
    "    vgg5.cuda()\n",
    "    matrix.cuda()\n",
    "    contentV = contentV.cuda()\n",
    "    styleV = styleV.cuda()\n",
    "print('14')\n",
    "################# TRAINING #################\n",
    "def adjust_learning_rate(optimizer, iteration):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr / (1+iteration*1e-5)\n",
    "# print('15')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for iteration in range(1,niter+1):\n",
    "    optimizer.zero_grad()\n",
    "#     print('16')\n",
    "    try:\n",
    "        content,_ = content_loader.next()\n",
    "    except IOError:\n",
    "        content,_ = content_loader.next()\n",
    "    except StopIteration:\n",
    "        content_loader = iter(content_loader_)\n",
    "        content,_ = content_loader.next()\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#     print('17')\n",
    "    try:\n",
    "        style,_ = style_loader.next()\n",
    "    except IOError:\n",
    "        style,_ = style_loader.next()\n",
    "    except StopIteration:\n",
    "        style_loader = iter(style_loader_)\n",
    "        style,_ = style_loader.next()\n",
    "    except:\n",
    "        continue\n",
    "#     print('18')\n",
    "    contentV.resize_(content.size()).copy_(content)\n",
    "    styleV.resize_(style.size()).copy_(style)\n",
    "#     print('19')\n",
    "    # forward\n",
    "    sF = vgg(styleV)\n",
    "    cF = vgg(contentV)\n",
    "\n",
    "    if(layer == 'r41'):\n",
    "        feature,transmatrix = matrix(cF[layer],sF[layer])\n",
    "    else:\n",
    "        feature,transmatrix = matrix(cF,sF)\n",
    "    transfer = dec(feature)\n",
    "\n",
    "    sF_loss = vgg5(styleV)\n",
    "    cF_loss = vgg5(contentV)\n",
    "    tF = vgg5(transfer)\n",
    "    loss,styleLoss,contentLoss = criterion(tF,sF_loss,cF_loss)\n",
    "#     print('20')\n",
    "    # backward & optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Iteration: [%d/%d] Loss: %.4f contentLoss: %.4f styleLoss: %.4f Learng Rate is %.6f'%\n",
    "         (niter,iteration,loss,contentLoss,styleLoss,optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    adjust_learning_rate(optimizer,iteration)\n",
    "\n",
    "#     if((iteration) % log_interval == 0):\n",
    "#         transfer = transfer.clamp(0,1)\n",
    "#         concat = torch.cat((content,style,transfer.cpu()),dim=0)\n",
    "#         vutils.save_image(concat,'%s/%d.png'%(outf,iteration),normalize=True,scale_each=True,nrow=batchSize)\n",
    "\n",
    "    if(iteration > 0 and (iteration) % save_interval == 0):\n",
    "        torch.save(matrix.state_dict(), '%s/%s.pth' % (outf,layer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
